{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import gym\n",
    "from gym import spaces\n",
    "import random as rd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from envs.NetworkOperatorEnv import NetworkOperatorEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Instantiate the env\n",
    "env = NetworkOperatorEnv(3, 30)\n",
    "# wrap it\n",
    "env = Monitor(env, filename=None, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:20: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9da0213450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9da0213450>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9da0213450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9da0213450>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9d1c473250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9d1c473250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9d1c473250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9d1c473250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:205: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:968: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "---------------------------------\n",
      "| explained_variance | -0.00019 |\n",
      "| fps                | 14       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.95     |\n",
      "| policy_loss        | 644      |\n",
      "| total_timesteps    | 0        |\n",
      "| value_loss         | 1.46e+05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 7.15e-07 |\n",
      "| fps                | 159      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.81     |\n",
      "| policy_loss        | 650      |\n",
      "| total_timesteps    | 2079     |\n",
      "| value_loss         | 1.79e+05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.00011  |\n",
      "| fps                | 163      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.72     |\n",
      "| policy_loss        | 387      |\n",
      "| total_timesteps    | 4179     |\n",
      "| value_loss         | 1.11e+05 |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ACKTR('MlpPolicy', env, verbose=1).learn(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Action:  [1]\n",
      "obs= [401] reward= [38.] done= [False]\n",
      "Step 2\n",
      "Action:  [1]\n",
      "obs= [453] reward= [30.] done= [False]\n",
      "Step 3\n",
      "Action:  [1]\n",
      "obs= [120] reward= [21.] done= [False]\n",
      "Step 4\n",
      "Action:  [1]\n",
      "obs= [217] reward= [30.] done= [False]\n",
      "Step 5\n",
      "Action:  [1]\n",
      "obs= [226] reward= [21.] done= [False]\n",
      "Step 6\n",
      "Action:  [1]\n",
      "obs= [217] reward= [30.] done= [False]\n",
      "Step 7\n",
      "Action:  [1]\n",
      "obs= [395] reward= [39.] done= [False]\n",
      "Step 8\n",
      "Action:  [1]\n",
      "obs= [149] reward= [29.] done= [False]\n",
      "Step 9\n",
      "Action:  [1]\n",
      "obs= [291] reward= [35.] done= [False]\n",
      "Step 10\n",
      "Action:  [1]\n",
      "obs= [10] reward= [27.] done= [False]\n",
      "Step 11\n",
      "Action:  [1]\n",
      "obs= [40] reward= [34.] done= [False]\n",
      "Step 12\n",
      "Action:  [1]\n",
      "obs= [483] reward= [28.] done= [False]\n",
      "Step 13\n",
      "Action:  [1]\n",
      "obs= [494] reward= [26.] done= [False]\n",
      "Step 14\n",
      "Action:  [1]\n",
      "obs= [441] reward= [14.] done= [False]\n",
      "Step 15\n",
      "Action:  [1]\n",
      "obs= [61] reward= [15.] done= [False]\n",
      "Step 16\n",
      "Action:  [1]\n",
      "obs= [53] reward= [32.] done= [False]\n",
      "Step 17\n",
      "Action:  [1]\n",
      "obs= [100] reward= [41.] done= [False]\n",
      "Step 18\n",
      "Action:  [1]\n",
      "obs= [123] reward= [40.] done= [False]\n",
      "Step 19\n",
      "Action:  [1]\n",
      "obs= [163] reward= [30.] done= [False]\n",
      "Step 20\n",
      "Action:  [1]\n",
      "obs= [261] reward= [45.] done= [False]\n",
      "Step 21\n",
      "Action:  [1]\n",
      "obs= [166] reward= [40.] done= [False]\n",
      "Step 22\n",
      "Action:  [1]\n",
      "obs= [432] reward= [37.] done= [False]\n",
      "Step 23\n",
      "Action:  [1]\n",
      "obs= [67] reward= [16.] done= [False]\n",
      "Step 24\n",
      "Action:  [1]\n",
      "obs= [413] reward= [29.] done= [False]\n",
      "Step 25\n",
      "Action:  [1]\n",
      "obs= [89] reward= [33.] done= [False]\n",
      "Step 26\n",
      "Action:  [1]\n",
      "obs= [39] reward= [34.] done= [False]\n",
      "Step 27\n",
      "Action:  [1]\n",
      "obs= [186] reward= [37.] done= [False]\n",
      "Step 28\n",
      "Action:  [1]\n",
      "obs= [487] reward= [39.] done= [False]\n",
      "Step 29\n",
      "Action:  [1]\n",
      "obs= [109] reward= [13.] done= [False]\n",
      "Step 30\n",
      "Action:  [1]\n",
      "obs= [423] reward= [52.] done= [False]\n",
      "Step 31\n",
      "Action:  [1]\n",
      "obs= [93] reward= [29.] done= [False]\n",
      "Step 32\n",
      "Action:  [1]\n",
      "obs= [99] reward= [21.] done= [False]\n",
      "Step 33\n",
      "Action:  [1]\n",
      "obs= [222] reward= [46.] done= [False]\n",
      "Step 34\n",
      "Action:  [1]\n",
      "obs= [240] reward= [32.] done= [False]\n",
      "Step 35\n",
      "Action:  [1]\n",
      "obs= [269] reward= [42.] done= [False]\n",
      "Step 36\n",
      "Action:  [1]\n",
      "obs= [388] reward= [41.] done= [False]\n",
      "Step 37\n",
      "Action:  [1]\n",
      "obs= [375] reward= [23.] done= [False]\n",
      "Step 38\n",
      "Action:  [1]\n",
      "obs= [141] reward= [44.] done= [False]\n",
      "Step 39\n",
      "Action:  [1]\n",
      "obs= [28] reward= [39.] done= [False]\n",
      "Step 40\n",
      "Action:  [1]\n",
      "obs= [95] reward= [41.] done= [False]\n",
      "Step 41\n",
      "Action:  [1]\n",
      "obs= [1] reward= [36.] done= [False]\n",
      "Step 42\n",
      "Action:  [1]\n",
      "obs= [283] reward= [26.] done= [False]\n",
      "Step 43\n",
      "Action:  [1]\n",
      "obs= [390] reward= [29.] done= [False]\n",
      "Step 44\n",
      "Action:  [1]\n",
      "obs= [37] reward= [34.] done= [False]\n",
      "Step 45\n",
      "Action:  [1]\n",
      "obs= [87] reward= [32.] done= [False]\n",
      "Step 46\n",
      "Action:  [1]\n",
      "obs= [248] reward= [36.] done= [False]\n",
      "Step 47\n",
      "Action:  [1]\n",
      "obs= [487] reward= [40.] done= [False]\n",
      "Step 48\n",
      "Action:  [1]\n",
      "obs= [259] reward= [18.] done= [False]\n",
      "Step 49\n",
      "Action:  [1]\n",
      "obs= [414] reward= [45.] done= [False]\n",
      "Step 50\n",
      "Action:  [1]\n",
      "obs= [433] reward= [32.] done= [False]\n",
      "Step 51\n",
      "Action:  [1]\n",
      "obs= [369] reward= [21.] done= [False]\n",
      "Step 52\n",
      "Action:  [1]\n",
      "obs= [91] reward= [32.] done= [False]\n",
      "Step 53\n",
      "Action:  [1]\n",
      "obs= [134] reward= [19.] done= [False]\n",
      "Step 54\n",
      "Action:  [1]\n",
      "obs= [169] reward= [44.] done= [False]\n",
      "Step 55\n",
      "Action:  [1]\n",
      "obs= [29] reward= [39.] done= [False]\n",
      "Step 56\n",
      "Action:  [1]\n",
      "obs= [111] reward= [34.] done= [False]\n",
      "Step 57\n",
      "Action:  [1]\n",
      "obs= [88] reward= [42.] done= [False]\n",
      "Step 58\n",
      "Action:  [1]\n",
      "obs= [460] reward= [44.] done= [False]\n",
      "Step 59\n",
      "Action:  [1]\n",
      "obs= [286] reward= [21.] done= [False]\n",
      "Step 60\n",
      "Action:  [1]\n",
      "obs= [494] reward= [34.] done= [False]\n",
      "Step 61\n",
      "Action:  [1]\n",
      "obs= [458] reward= [19.] done= [False]\n",
      "Step 62\n",
      "Action:  [1]\n",
      "obs= [115] reward= [20.] done= [False]\n",
      "Step 63\n",
      "Action:  [1]\n",
      "obs= [267] reward= [43.] done= [False]\n",
      "Step 64\n",
      "Action:  [1]\n",
      "obs= [157] reward= [36.] done= [False]\n",
      "Step 65\n",
      "Action:  [1]\n",
      "obs= [380] reward= [43.] done= [False]\n",
      "Step 66\n",
      "Action:  [1]\n",
      "obs= [215] reward= [36.] done= [False]\n",
      "Step 67\n",
      "Action:  [1]\n",
      "obs= [48] reward= [34.] done= [False]\n",
      "Step 68\n",
      "Action:  [1]\n",
      "obs= [265] reward= [44.] done= [False]\n",
      "Step 69\n",
      "Action:  [1]\n",
      "obs= [320] reward= [23.] done= [False]\n",
      "Step 70\n",
      "Action:  [1]\n",
      "obs= [357] reward= [28.] done= [False]\n",
      "Step 71\n",
      "Action:  [1]\n",
      "obs= [170] reward= [40.] done= [False]\n",
      "Step 72\n",
      "Action:  [1]\n",
      "obs= [141] reward= [38.] done= [False]\n",
      "Step 73\n",
      "Action:  [1]\n",
      "obs= [166] reward= [32.] done= [False]\n",
      "Step 74\n",
      "Action:  [1]\n",
      "obs= [15] reward= [35.] done= [False]\n",
      "Step 75\n",
      "Action:  [1]\n",
      "obs= [362] reward= [44.] done= [False]\n",
      "Step 76\n",
      "Action:  [1]\n",
      "obs= [313] reward= [41.] done= [False]\n",
      "Step 77\n",
      "Action:  [1]\n",
      "obs= [88] reward= [32.] done= [False]\n",
      "Step 78\n",
      "Action:  [1]\n",
      "obs= [467] reward= [41.] done= [False]\n",
      "Step 79\n",
      "Action:  [1]\n",
      "obs= [380] reward= [28.] done= [False]\n",
      "Step 80\n",
      "Action:  [1]\n",
      "obs= [365] reward= [38.] done= [False]\n",
      "Step 81\n",
      "Action:  [1]\n",
      "obs= [217] reward= [30.] done= [False]\n",
      "Step 82\n",
      "Action:  [1]\n",
      "obs= [228] reward= [32.] done= [False]\n",
      "Step 83\n",
      "Action:  [1]\n",
      "obs= [339] reward= [49.] done= [False]\n",
      "Step 84\n",
      "Action:  [1]\n",
      "obs= [94] reward= [34.] done= [False]\n",
      "Step 85\n",
      "Action:  [1]\n",
      "obs= [478] reward= [29.] done= [False]\n",
      "Step 86\n",
      "Action:  [1]\n",
      "obs= [493] reward= [25.] done= [False]\n",
      "Step 87\n",
      "Action:  [1]\n",
      "obs= [294] reward= [17.] done= [False]\n",
      "Step 88\n",
      "Action:  [1]\n",
      "obs= [68] reward= [34.] done= [False]\n",
      "Step 89\n",
      "Action:  [1]\n",
      "obs= [495] reward= [41.] done= [False]\n",
      "Step 90\n",
      "Action:  [1]\n",
      "obs= [216] reward= [5.] done= [False]\n",
      "Step 91\n",
      "Action:  [1]\n",
      "obs= [195] reward= [47.] done= [False]\n",
      "Step 92\n",
      "Action:  [1]\n",
      "obs= [472] reward= [40.] done= [False]\n",
      "Step 93\n",
      "Action:  [1]\n",
      "obs= [214] reward= [25.] done= [False]\n",
      "Step 94\n",
      "Action:  [1]\n",
      "obs= [26] reward= [28.] done= [False]\n",
      "Step 95\n",
      "Action:  [1]\n",
      "obs= [177] reward= [44.] done= [False]\n",
      "Step 96\n",
      "Action:  [1]\n",
      "obs= [35] reward= [42.] done= [False]\n",
      "Step 97\n",
      "Action:  [1]\n",
      "obs= [160] reward= [28.] done= [False]\n",
      "Step 98\n",
      "Action:  [1]\n",
      "obs= [254] reward= [47.] done= [False]\n",
      "Step 99\n",
      "Action:  [1]\n",
      "obs= [16] reward= [30.] done= [False]\n",
      "Step 100\n",
      "Action:  [1]\n",
      "obs= [390] reward= [46.] done= [False]\n",
      "Step 101\n",
      "Action:  [1]\n",
      "obs= [219] reward= [22.] done= [False]\n",
      "Step 102\n",
      "Action:  [1]\n",
      "obs= [490] reward= [44.] done= [False]\n",
      "Step 103\n",
      "Action:  [1]\n",
      "obs= [156] reward= [30.] done= [False]\n",
      "Step 104\n",
      "Action:  [1]\n",
      "obs= [257] reward= [38.] done= [False]\n",
      "Step 105\n",
      "Action:  [1]\n",
      "obs= [288] reward= [39.] done= [False]\n",
      "Step 106\n",
      "Action:  [1]\n",
      "obs= [338] reward= [38.] done= [False]\n",
      "Step 107\n",
      "Action:  [1]\n",
      "obs= [415] reward= [44.] done= [False]\n",
      "Step 108\n",
      "Action:  [1]\n",
      "obs= [161] reward= [19.] done= [False]\n",
      "Step 109\n",
      "Action:  [1]\n",
      "obs= [277] reward= [38.] done= [False]\n",
      "Step 110\n",
      "Action:  [1]\n",
      "obs= [399] reward= [44.] done= [False]\n",
      "Step 111\n",
      "Action:  [1]\n",
      "obs= [422] reward= [30.] done= [False]\n",
      "Step 112\n",
      "Action:  [1]\n",
      "obs= [495] reward= [31.] done= [False]\n",
      "Step 113\n",
      "Action:  [1]\n",
      "obs= [396] reward= [15.] done= [False]\n",
      "Step 114\n",
      "Action:  [1]\n",
      "obs= [105] reward= [31.] done= [False]\n",
      "Step 115\n",
      "Action:  [1]\n",
      "obs= [52] reward= [37.] done= [False]\n",
      "Step 116\n",
      "Action:  [1]\n",
      "obs= [67] reward= [43.] done= [False]\n",
      "Step 117\n",
      "Action:  [1]\n",
      "obs= [16] reward= [30.] done= [False]\n",
      "Step 118\n",
      "Action:  [1]\n",
      "obs= [223] reward= [39.] done= [False]\n",
      "Step 119\n",
      "Action:  [1]\n",
      "obs= [228] reward= [39.] done= [False]\n",
      "Step 120\n",
      "Action:  [1]\n",
      "obs= [457] reward= [45.] done= [False]\n",
      "Step 121\n",
      "Action:  [1]\n",
      "obs= [24] reward= [26.] done= [False]\n",
      "Step 122\n",
      "Action:  [1]\n",
      "obs= [113] reward= [45.] done= [False]\n",
      "Step 123\n",
      "Action:  [1]\n",
      "obs= [483] reward= [41.] done= [False]\n",
      "Step 124\n",
      "Action:  [1]\n",
      "obs= [448] reward= [28.] done= [False]\n",
      "Step 125\n",
      "Action:  [1]\n",
      "obs= [438] reward= [30.] done= [False]\n",
      "Step 126\n",
      "Action:  [1]\n",
      "obs= [312] reward= [23.] done= [False]\n",
      "Step 127\n",
      "Action:  [1]\n",
      "obs= [159] reward= [30.] done= [False]\n",
      "Step 128\n",
      "Action:  [1]\n",
      "obs= [362] reward= [29.] done= [False]\n",
      "Step 129\n",
      "Action:  [1]\n",
      "obs= [222] reward= [34.] done= [False]\n",
      "Step 130\n",
      "Action:  [1]\n",
      "obs= [88] reward= [41.] done= [False]\n",
      "Step 131\n",
      "Action:  [1]\n",
      "obs= [439] reward= [37.] done= [False]\n",
      "Step 132\n",
      "Action:  [1]\n",
      "obs= [299] reward= [24.] done= [False]\n",
      "Step 133\n",
      "Action:  [1]\n",
      "obs= [409] reward= [35.] done= [False]\n",
      "Step 134\n",
      "Action:  [1]\n",
      "obs= [108] reward= [32.] done= [False]\n",
      "Step 135\n",
      "Action:  [1]\n",
      "obs= [268] reward= [41.] done= [False]\n",
      "Step 136\n",
      "Action:  [1]\n",
      "obs= [212] reward= [27.] done= [False]\n",
      "Step 137\n",
      "Action:  [1]\n",
      "obs= [307] reward= [50.] done= [False]\n",
      "Step 138\n",
      "Action:  [1]\n",
      "obs= [69] reward= [12.] done= [False]\n",
      "Step 139\n",
      "Action:  [1]\n",
      "obs= [490] reward= [41.] done= [False]\n",
      "Step 140\n",
      "Action:  [1]\n",
      "obs= [388] reward= [18.] done= [False]\n",
      "Step 141\n",
      "Action:  [1]\n",
      "obs= [342] reward= [35.] done= [False]\n",
      "Step 142\n",
      "Action:  [1]\n",
      "obs= [324] reward= [32.] done= [False]\n",
      "Step 143\n",
      "Action:  [1]\n",
      "obs= [158] reward= [33.] done= [False]\n",
      "Step 144\n",
      "Action:  [1]\n",
      "obs= [391] reward= [46.] done= [False]\n",
      "Step 145\n",
      "Action:  [1]\n",
      "obs= [403] reward= [30.] done= [False]\n",
      "Step 146\n",
      "Action:  [1]\n",
      "obs= [39] reward= [27.] done= [False]\n",
      "Step 147\n",
      "Action:  [1]\n",
      "obs= [157] reward= [42.] done= [False]\n",
      "Step 148\n",
      "Action:  [1]\n",
      "obs= [138] reward= [43.] done= [False]\n",
      "Step 149\n",
      "Action:  [1]\n",
      "obs= [139] reward= [32.] done= [False]\n",
      "Step 150\n",
      "Action:  [1]\n",
      "obs= [316] reward= [42.] done= [False]\n",
      "Step 151\n",
      "Action:  [1]\n",
      "obs= [430] reward= [44.] done= [False]\n",
      "Step 152\n",
      "Action:  [1]\n",
      "obs= [73] reward= [17.] done= [False]\n",
      "Step 153\n",
      "Action:  [1]\n",
      "obs= [225] reward= [41.] done= [False]\n",
      "Step 154\n",
      "Action:  [1]\n",
      "obs= [10] reward= [30.] done= [False]\n",
      "Step 155\n",
      "Action:  [1]\n",
      "obs= [416] reward= [37.] done= [False]\n",
      "Step 156\n",
      "Action:  [1]\n",
      "obs= [58] reward= [31.] done= [False]\n",
      "Step 157\n",
      "Action:  [1]\n",
      "obs= [99] reward= [36.] done= [False]\n",
      "Step 158\n",
      "Action:  [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs= [489] reward= [43.] done= [False]\n",
      "Step 159\n",
      "Action:  [1]\n",
      "obs= [11] reward= [16.] done= [False]\n",
      "Step 160\n",
      "Action:  [1]\n",
      "obs= [395] reward= [41.] done= [False]\n",
      "Step 161\n",
      "Action:  [1]\n",
      "obs= [333] reward= [37.] done= [False]\n",
      "Step 162\n",
      "Action:  [1]\n",
      "obs= [65] reward= [37.] done= [False]\n",
      "Step 163\n",
      "Action:  [1]\n",
      "obs= [414] reward= [31.] done= [False]\n",
      "Step 164\n",
      "Action:  [1]\n",
      "obs= [373] reward= [29.] done= [False]\n",
      "Step 165\n",
      "Action:  [1]\n",
      "obs= [349] reward= [28.] done= [False]\n",
      "Step 166\n",
      "Action:  [1]\n",
      "obs= [149] reward= [32.] done= [False]\n",
      "Step 167\n",
      "Action:  [1]\n",
      "obs= [143] reward= [31.] done= [False]\n",
      "Step 168\n",
      "Action:  [1]\n",
      "obs= [185] reward= [44.] done= [False]\n",
      "Step 169\n",
      "Action:  [1]\n",
      "obs= [436] reward= [44.] done= [False]\n",
      "Step 170\n",
      "Action:  [1]\n",
      "obs= [267] reward= [31.] done= [False]\n",
      "Step 171\n",
      "Action:  [1]\n",
      "obs= [182] reward= [24.] done= [False]\n",
      "Step 172\n",
      "Action:  [1]\n",
      "obs= [490] reward= [35.] done= [False]\n",
      "Step 173\n",
      "Action:  [1]\n",
      "obs= [375] reward= [22.] done= [False]\n",
      "Step 174\n",
      "Action:  [1]\n",
      "obs= [265] reward= [32.] done= [False]\n",
      "Step 175\n",
      "Action:  [1]\n",
      "obs= [58] reward= [23.] done= [False]\n",
      "Step 176\n",
      "Action:  [1]\n",
      "obs= [335] reward= [40.] done= [False]\n",
      "Step 177\n",
      "Action:  [1]\n",
      "obs= [474] reward= [37.] done= [False]\n",
      "Step 178\n",
      "Action:  [1]\n",
      "obs= [146] reward= [20.] done= [False]\n",
      "Step 179\n",
      "Action:  [1]\n",
      "obs= [397] reward= [28.] done= [False]\n",
      "Step 180\n",
      "Action:  [1]\n",
      "obs= [459] reward= [32.] done= [False]\n",
      "Step 181\n",
      "Action:  [1]\n",
      "obs= [495] reward= [30.] done= [False]\n",
      "Step 182\n",
      "Action:  [1]\n",
      "obs= [2] reward= [23.] done= [False]\n",
      "Step 183\n",
      "Action:  [1]\n",
      "obs= [243] reward= [35.] done= [False]\n",
      "Step 184\n",
      "Action:  [1]\n",
      "obs= [268] reward= [22.] done= [False]\n",
      "Step 185\n",
      "Action:  [1]\n",
      "obs= [427] reward= [35.] done= [False]\n",
      "Step 186\n",
      "Action:  [1]\n",
      "obs= [40] reward= [33.] done= [False]\n",
      "Step 187\n",
      "Action:  [1]\n",
      "obs= [341] reward= [37.] done= [False]\n",
      "Step 188\n",
      "Action:  [1]\n",
      "obs= [13] reward= [28.] done= [False]\n",
      "Step 189\n",
      "Action:  [1]\n",
      "obs= [146] reward= [42.] done= [False]\n",
      "Step 190\n",
      "Action:  [1]\n",
      "obs= [48] reward= [19.] done= [False]\n",
      "Step 191\n",
      "Action:  [1]\n",
      "obs= [387] reward= [40.] done= [False]\n",
      "Step 192\n",
      "Action:  [1]\n",
      "obs= [407] reward= [29.] done= [False]\n",
      "Step 193\n",
      "Action:  [1]\n",
      "obs= [268] reward= [38.] done= [False]\n",
      "Step 194\n",
      "Action:  [1]\n",
      "obs= [459] reward= [33.] done= [False]\n",
      "Step 195\n",
      "Action:  [1]\n",
      "obs= [460] reward= [26.] done= [False]\n",
      "Step 196\n",
      "Action:  [1]\n",
      "obs= [262] reward= [17.] done= [False]\n",
      "Step 197\n",
      "Action:  [1]\n",
      "obs= [167] reward= [31.] done= [False]\n",
      "Step 198\n",
      "Action:  [1]\n",
      "obs= [469] reward= [38.] done= [False]\n",
      "Step 199\n",
      "Action:  [1]\n",
      "obs= [391] reward= [29.] done= [False]\n",
      "Step 200\n",
      "Action:  [1]\n",
      "obs= [40] reward= [22.] done= [False]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "n_steps = 2000\n",
    "for step in range(n_steps):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    print(\"Step {}\".format(step + 1))\n",
    "    print(\"Action: \", action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print('obs=', obs, 'reward=', reward, 'done=', done)\n",
    "    #env.render(mode='console')\n",
    "    if done:\n",
    "        # Note that the VecEnv resets automatically\n",
    "        # when a done signal is encountered\n",
    "        print(\"Goal reached!\", \"reward=\", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
